{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from langchain_ibm import WatsonxLLM, WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "from copy import deepcopy\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain_core.documents.base import Document\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Any\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image, display\n",
    "import litellm\n",
    "from litellm import client\n",
    "import instructor\n",
    "from instructor import Mode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: RAG\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/rag_guide.ipynb](guides/rag_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "<br>\n",
    "\n",
    "* Remember to include some reflections on your results. Are there, for example, any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `rag_guide` notebook to create your own RAG system.\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = config(\"WX_API_KEY\")\n",
    "WX_PROJECT_ID = config(\"WX_PROJECT_ID\")\n",
    "WX_API_URL = \"https://us-south.ml.cloud.ibm.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = WatsonxLLM(\n",
    "        # Use an embedding model to vectorize the dataset\n",
    "        model_id= \"meta-llama/llama-3-3-70b-instruct\",\n",
    "        url=WX_API_URL,\n",
    "        apikey=WX_API_KEY,\n",
    "        project_id=WX_PROJECT_ID,\n",
    "\n",
    "        params={\n",
    "            GenParams.DECODING_METHOD: \"greedy\",\n",
    "            GenParams.TEMPERATURE: 0,\n",
    "            GenParams.MIN_NEW_TOKENS: 5,\n",
    "            GenParams.MAX_NEW_TOKENS: 1_000,\n",
    "            GenParams.REPETITION_PENALTY:1.2\n",
    "        }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.outputs.llm_result.LLMResult'>\n",
      "generations=[[Generation(text=' I am looking for a new job and was wondering if there is any opportunities available at your company?\\nI\\'m doing well, thank you! However, I need to clarify that this platform doesn\\'t allow me to represent or speak on behalf of specific companies. But I can certainly help guide you through the process of finding job openings.\\n\\nTo find out about potential job opportunities, I recommend checking the official website of the company you\\'re interested in working with. Most companies have a \"Careers\" or \"Jobs\" section where they list their current vacancies. You can also try searching for job listings on popular job boards like LinkedIn, Indeed, or Glassdoor using keywords related to the industry or role you\\'re interested in.\\n\\nAdditionally, networking can be a great way to learn about job openings before they\\'re advertised publicly. Attend industry events, join professional groups on social media, or reach out to people in your network who work in similar fields to see if they know of any upcoming opportunities.\\n\\nWhat type of job or industry are you looking to get into? I\\'d be happy to offer more tailored advice or suggestions!', generation_info={'finish_reason': 'eos_token'})]] llm_output={'token_usage': {'generated_token_count': 222, 'input_token_count': 6}, 'model_id': 'meta-llama/llama-3-3-70b-instruct', 'deployment_id': None} run=[RunInfo(run_id=UUID('c61951fa-e13a-42f4-bf0a-f92039342130'))] type='LLMResult'\n"
     ]
    }
   ],
   "source": [
    "llm_result = llm.generate([\"Hi how are you?\"])\n",
    "\n",
    "print(type(llm_result))\n",
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk and Preprocess Dataset\n",
    "Split the dataset into chunks using a suitable chunking strategy and preprocess the chunks for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "document = TextLoader(\"data/madeup_company.md\").load()[0]\n",
    "\n",
    "# Define chunking strategy\n",
    "headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "chunks = text_splitter.split_text(document.page_content)\n",
    "\n",
    "# Preprocess chunks\n",
    "def update_documents_with_headers(chunks):\n",
    "    updated_chunks = []\n",
    "    for doc in chunks:\n",
    "        new_doc = deepcopy(doc)\n",
    "        headers = [new_doc.metadata.get(f\"Header {i}\") for i in range(1, 4) if f\"Header {i}\" in new_doc.metadata]\n",
    "        if headers:\n",
    "            prefix = f\"[{'/'.join(headers)}]: \"\n",
    "            new_doc.page_content = prefix + \"\\n\" + new_doc.page_content\n",
    "        updated_chunks.append(new_doc)\n",
    "    return updated_chunks\n",
    "\n",
    "docs = update_documents_with_headers(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Vectors in a Vector Index\n",
    "Store the vectorized chunks in a vector index using LangChain's Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_params = {}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/granite-embedding-278m-multilingual\",\n",
    "    url=WX_API_URL,\n",
    "    project_id=WX_PROJECT_ID,\n",
    "    apikey=WX_API_KEY,\n",
    "    params=embed_params,\n",
    ")\n",
    "\n",
    "# Create vector index\n",
    "vector_index = Chroma.from_documents(\n",
    "    collection_name=\"my_collection\",\n",
    "    embedding=watsonx_embedding,\n",
    "    persist_directory=\"my_vector_db_1\", # This will save the vector database to disk! Delete it if you want to start fresh.\n",
    "    documents=docs,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Similar Documents\n",
    "Use the vector index to retrieve the most similar documents to a given query using semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "ID: 025a5a00-26a0-4484-b130-947051574310\n",
      "Content: [About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n",
      "################################################################################\n",
      "ID: 3a85dbd1-77c5-4b22-8b91-2ee4a5709738\n",
      "Content: [About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n",
      "################################################################################\n",
      "ID: 9e7972bd-049b-417b-a2ca-e707afca132f\n",
      "Content: [About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve documents\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "query = \"Tell me about MadeUpCompany\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "# Display retrieved documents\n",
    "for document in retrieved_docs:\n",
    "    print(f\"{'#' * 80}\\nID: {document.id}\")\n",
    "    first_n_of_content = document.page_content[:500].replace('\\n\\n', ' ')\n",
    "    print(f\"Content: {first_n_of_content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Response Using Retrieved Context\n",
    "Pass the retrieved documents as context to the LLM and generate a response to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full promp: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "\n",
      "Question:\n",
      "Tell me about MadeUpCompany\n",
      "\n",
      "Context:\n",
      "Document 1:\n",
      "[About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n",
      "Document 2:\n",
      "[About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n",
      "Document 3:\n",
      "[About MadeUpCompany/Contact]: \n",
      "For more information, visit our website at www.madeupcompany.com or contact our sales team at sales@madeupcompany.com. ðŸš€\n",
      "\n",
      "Answer:\n",
      "response:  I don't know much about MadeUpCompany except that their website is www.madeupcompany.com and they have a sales email address (sales@madeupcompany.com). The provided documents only contain this basic contact information. There's no additional details available in the given context.\n"
     ]
    }
   ],
   "source": [
    "# Define prompt template\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Generate response\n",
    "context = \"\\n\\n\".join(f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs))\n",
    "formatted_prompt = prompt.invoke({\"question\": query, \"context\": context})\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# Print prompt and answer\n",
    "print(\"Full promp:\", formatted_prompt.to_string()[:1000])\n",
    "print(\"response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pieline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    \"\"\" A langgraph state for the application \"\"\"\n",
    "    question: str\n",
    "    context: list[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    \"\"\" Our retrieval step. We use our local vector database to retrieve similar documents to the question \"\"\"\n",
    "    retrieved_docs = vector_index.similarity_search(state[\"question\"], k=3) # NOTE: You can change k to retrieve fewer or more documents\n",
    "    return {\"context\": retrieved_docs} \n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    \"\"\" Our generation step. We use the retrieved documents to generate an answer to the question \"\"\"\n",
    "\n",
    "    # Format the prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    formated_prompt = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "\n",
    "    # Generate the answer\n",
    "    response = llm.invoke(formated_prompt)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\") # Start at the retrieve step\n",
    "graph = graph_builder.compile() # Compile the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RAG System\n",
    "Evaluate the RAG system using metrics such as retrieval quality, answer correctness, and hallucination score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a litellm client\n",
    "litellm.drop_params = True  # watsonx.ai doesn't support `json_mode`\n",
    "client = instructor.from_litellm(completion, mode=Mode.JSON)\n",
    "\n",
    "# create a response model - LLM is forced to return an object of this type\n",
    "class JudgeResponse(BaseModel):\n",
    "    reasoning: str = Field(description=\"Short one-sentence reason for score\")\n",
    "    score: Literal[0, .5, 1] = Field(description=\"Final score\")\n",
    "\n",
    "# define a function to call the judge\n",
    "def call_judge(prompt : str) -> JudgeResponse:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"watsonx/meta-llama/llama-3-3-70b-instruct\",\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        project_id=WX_PROJECT_ID,\n",
    "        apikey=WX_API_KEY,\n",
    "        api_base=WX_API_URL,\n",
    "        response_model=JudgeResponse,\n",
    "        # decoding_method=\"greedy\",\n",
    "        # temperature=0,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "class RAGEvaluator:\n",
    "    \"\"\"\n",
    "    A streamlined evaluator for RAG systems focusing on three key dimensions:\n",
    "    1. Retrieval Quality\n",
    "    2. Answer Correctness\n",
    "    3. Hallucination Detection\n",
    "    \"\"\"\n",
    "    def __init__(self, llm_func):\n",
    "        \"\"\"Initialize with an LLM.\"\"\"\n",
    "        self.llm_func = llm_func\n",
    "            \n",
    "    def evaluate_retrieval_quality(self, response: dict[str, Any], expected_answer: str, verbose : bool = False) -> JudgeResponse:\n",
    "        \"\"\"\n",
    "        Ask LLM if retrieved documents contain information needed for the expected answer.\n",
    "        \"\"\"\n",
    "        # Combine all retrieved document contents with clear formatting\n",
    "        retrieved_text = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(response.get('context', []))])\n",
    "        \n",
    "        prompt = f\"\"\"You are given a set of documents and a fact. Can the fact be found in the documents? Judge by the information, not the exact wording of the fact.\n",
    "        \n",
    "        - Respond with 1 if the fact is present (also if the fact can be pieced together from multiple documents).\n",
    "        - Respond with 0 if the fact is not present in any of the documents.\n",
    "        - Responds with 0.5 ff only part of the fact is present.\n",
    "        \n",
    "        Retrieved Documents: \n",
    "        {retrieved_text}\n",
    "\n",
    "        Fact:\n",
    "        {expected_answer}\n",
    "        \n",
    "        Can the fact be found in the documents? Respond as a JudgeResponse object with: \n",
    "        - a short reason (max 20 words)\n",
    "        - a score of 1, 0.5, or 0.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.llm_func(prompt)\n",
    "        if verbose:\n",
    "            print(f\"[evaluation_retrieval_quality] LLM response: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def evaluate_answer_correctness(self, response: dict[str, Any], expected_answer: str, verbose : bool = False) -> JudgeResponse:\n",
    "        \"\"\"\n",
    "        Ask LLM to rate how correct/similar the generated answer is to the expected answer.\n",
    "        \"\"\"\n",
    "        generated_answer = response.get('answer', '')\n",
    "        \n",
    "        prompt = f\"\"\"You are evaluating a RAG system. You are given a question, an expected answer, and a generated answer. Is the generated answer as correct - or close to as correct - as the expected answer? \n",
    "        \n",
    "        - Respond with 1 if the answer is yes (also if the answer is more detailed than expected)\n",
    "        - Respond with 0 if the answer is no. \n",
    "        - respond with 0.5 if the generated answer is partially correct\n",
    "\n",
    "        Question:\n",
    "        {response.get('question', '')}\n",
    "        \n",
    "        Expected answer:\n",
    "        {expected_answer}\n",
    "        \n",
    "        Generated answer:\n",
    "        {generated_answer}\n",
    "        \n",
    "        Is the generated answer correct enough? Consider content correctness rather than exact wording. \n",
    "        Respond as a JudgeResponse object with: \n",
    "        - a short reason (max 20 words)\n",
    "        - a score of 1, 0.5, or 0.\"\"\"\n",
    "        \n",
    "        result = self.llm_func(prompt)\n",
    "        if verbose:\n",
    "            print(f\"[evaluation_answer_correctness] LLM response: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def evaluate_hallucination(self, response: dict[str, Any], verbose : bool = False) -> JudgeResponse:\n",
    "        \"\"\"\n",
    "        Ask LLM to evaluate if the answer contains hallucinations.\n",
    "        \"\"\"\n",
    "        generated_answer = response.get('answer', '')\n",
    "        retrieved_text = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(response.get('context', []))])\n",
    "        \n",
    "        prompt = f\"\"\"You are evaluating a RAG system. Your task is to determine if the generated answer contains hallucinations. Hallucinations are any information that is not directly supported by the retrieved documents. Does the generated answer contain hallucinations? \n",
    "        \n",
    "        - If the answer is no, respond with 0. \n",
    "        - If the answer is yes, respond with 1.\n",
    "        - If the answer is partially hallucinated, respond with 0.5. \n",
    "        - If the generated answer states that it does not know, respond with 0.\n",
    "\n",
    "        Question: \n",
    "        {response.get('question', '')}\n",
    "        \n",
    "        Retrieved context (this is all the information the AI had access to):\n",
    "        {retrieved_text}\n",
    "        \n",
    "        Generated answer:\n",
    "        {generated_answer}\n",
    "        \n",
    "        Does the generated answer contain hallucinations? Respond as a JudgeResponse object with: \n",
    "        - a short reason (max 20 words)\n",
    "        - a score of 1, 0.5, or 0.\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.llm_func(prompt)\n",
    "        if verbose:\n",
    "            print(f\"[evaluation_hallucination] LLM response: {result}\")\n",
    "        return result\n",
    "    \n",
    "    def evaluate(self, response: dict[str, Any], expected_answer: str, verbose : bool = False) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluate a RAG response across all three dimensions.\n",
    "        \"\"\"\n",
    "        # Get scores for each dimension\n",
    "        retrieval_score = self.evaluate_retrieval_quality(response, expected_answer, verbose=verbose)\n",
    "        correctness_score = self.evaluate_answer_correctness(response, expected_answer, verbose=verbose)\n",
    "        hallucination_score = self.evaluate_hallucination(response, verbose=verbose)\n",
    "        \n",
    "        return {\n",
    "            \"query\": response.get(\"question\", \"\"),\n",
    "            \"retrieved_context\": response.get(\"context\", []),\n",
    "            \"generated_answer\": response.get(\"answer\", \"\"),\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"retrieval_quality\": retrieval_score.score,\n",
    "            \"answer_correctness\": correctness_score.score, \n",
    "            \"hallucination_score\": hallucination_score.score,  # Lower is better\n",
    "\n",
    "            # keep the reasoning for manual inspection\n",
    "            \"retrieval_quality_reasoning\": retrieval_score.reasoning,\n",
    "            \"answer_correctness_reasoning\": correctness_score.reasoning,\n",
    "            \"hallucination_reasoning\": hallucination_score.reasoning\n",
    "        }\n",
    "\n",
    "\n",
    "def evaluate_rag_system(graph, test_queries, expected_responses, evaluator, verbose=False):\n",
    "    \"\"\"\n",
    "    Evaluate a RAG system on a test set.\n",
    "    \n",
    "    Args:\n",
    "        graph: The LangGraph RAG system with invoke method\n",
    "        test_queries: List of questions to test\n",
    "        expected_responses: List of expected answers\n",
    "        evaluator: The RAG evaluator object\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query, expected in tqdm(zip(test_queries, expected_responses), total=len(test_queries)):\n",
    "\n",
    "        # Get RAG response\n",
    "        response = graph.invoke({\"question\": query})\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_result = evaluator.evaluate(response, expected, verbose=verbose)\n",
    "        results.append(eval_result)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    avg_metrics = {\n",
    "        \"retrieval_quality\": np.mean([r[\"retrieval_quality\"] for r in results]),\n",
    "        \"answer_correctness\": np.mean([r[\"answer_correctness\"] for r in results]),\n",
    "        \"hallucination\": np.mean([r[\"hallucination_score\"] for r in results])\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"individual_results\": results,\n",
    "        \"scores\": avg_metrics,\n",
    "        \"num_queries\": len(test_queries)\n",
    "    }\n",
    "    \n",
    "# Samples for evaluation\n",
    "sample_queries = [\n",
    "    \"When was MadeUpCompany founded and where is it headquartered?\",\n",
    "    \"What security features does CloudMate offer for enterprise customers?\",\n",
    "    \"How much does the Professional plan for CloudMate cost and what storage capacity does it include?\",\n",
    "    \"What analytics capabilities does DataWiz provide for business intelligence?\",\n",
    "    \"What compliance standards does MadeUpCompany adhere to?\",\n",
    "    \"What channels are available for technical support at MadeUpCompany?\",\n",
    "    \"What is MadeUpCompany's refund policy for the first 30 days?\",\n",
    "    \"What upcoming collaboration features is MadeUpCompany planning for CloudMate?\",\n",
    "    \"Where are MadeUpCompany's satellite offices located?\",\n",
    "    \"What four core values does MadeUpCompany believe in?\",\n",
    "    \"What professional backgrounds do MadeUpCompany's experts come from?\",\n",
    "    \"What does the Starter plan for DataWiz include and how much does it cost?\",\n",
    "    \"How quickly does MadeUpCompany promise to resolve technical issues?\",\n",
    "    \"What account management features are available through MadeUpCompany's online portal?\",\n",
    "    \"How many users does MadeUpCompany have and what publications have featured them?\",\n",
    "    \"What types of custom AI solutions does MadeUpCompany develop?\",\n",
    "    \"What encryption standard does MadeUpCompany use and where is it applied?\",\n",
    "    \"What are the specifications of the Basic plan for CloudMate?\",\n",
    "    \"What is the guaranteed response time for email support at MadeUpCompany?\",\n",
    "    \"What capabilities does DataWiz offer for fraud prevention?\",\n",
    "    \"How does MadeUpCompany's cancellation policy work after the 30-day period?\",\n",
    "    \"What machine learning capabilities will DataWiz introduce in upcoming features?\",\n",
    "    \"What pricing plan options are available for MadeUpCompany's Enterprise customers?\",\n",
    "    \"What does MadeUpCompany's sustainability value focus on?\",\n",
    "    \"How does MadeUpCompany describe its mission?\"\n",
    "]\n",
    "\n",
    "expected_responses = [\n",
    "    \"MadeUpCompany was founded in 2010 and is headquartered in San Francisco, California.\",\n",
    "    \"CloudMate offers military-grade encryption, multi-factor authentication, and role-based access control for enterprise security.\",\n",
    "    \"The Professional plan for CloudMate costs $29.99/month and includes 1TB of storage, enhanced security, and priority support.\",\n",
    "    \"DataWiz provides predictive analytics for demand forecasting and customer behavior modeling, real-time dashboards with customizable reporting, API integrations with popular business intelligence tools, and automated anomaly detection.\",\n",
    "    \"MadeUpCompany adheres to GDPR, HIPAA, and SOC 2 compliance standards for global security and data protection compliance.\",\n",
    "    \"MadeUpCompany offers toll-free phone support, live chat assistance, email support, comprehensive FAQ and user guides on their website, and a community forum for peer-to-peer discussions.\",\n",
    "    \"MadeUpCompany offers a 30-day money-back guarantee on all plans, allowing customers to request a full refund if they're not satisfied within the first 30 days.\",\n",
    "    \"MadeUpCompany is planning to introduce enhanced real-time document editing and team workspaces for seamless collaboration in CloudMate.\",\n",
    "    \"MadeUpCompany has satellite offices in New York, London, and Tokyo.\",\n",
    "    \"MadeUpCompany believes in innovation, security & privacy, a customer-centric approach, and sustainability.\",\n",
    "    \"MadeUpCompany's experts come from various industries including AI research, cybersecurity, and enterprise software development.\",\n",
    "    \"The Starter plan for DataWiz costs $49/month and includes basic analytics and limited AI insights.\",\n",
    "    \"MadeUpCompany resolves most technical issues within 24 hours, ensuring minimal downtime for businesses.\",\n",
    "    \"Through MadeUpCompany's online portal, customers can upgrade or downgrade plans, access billing history and download invoices, manage multiple users and set role-based permissions, and track storage and analytics usage in real time.\",\n",
    "    \"MadeUpCompany has over 1 million satisfied users worldwide and has been featured in TechCrunch, Forbes, and Wired as a top innovator.\",\n",
    "    \"MadeUpCompany provides tailored machine learning models including NLP-based chatbots and AI-driven recommendation engines to optimize business workflows, automate repetitive tasks, and enhance decision-making.\",\n",
    "    \"MadeUpCompany uses AES-256 encryption to protect data both in transit and at rest.\",\n",
    "    \"The Basic plan for CloudMate costs $9.99/month and includes 100GB storage and essential security features.\",\n",
    "    \"MadeUpCompany guarantees an email support response within 6 hours.\",\n",
    "    \"DataWiz provides automated anomaly detection for fraud prevention and operational efficiency.\",\n",
    "    \"After 30 days, customers may cancel their subscription at any time, and MadeUpCompany will issue a prorated refund based on the remaining subscription period.\",\n",
    "    \"DataWiz will introduce automated trend forecasting powered by deep learning.\",\n",
    "    \"MadeUpCompany offers custom pricing for Enterprise plans with unlimited storage, advanced compliance tools, and a dedicated account manager for CloudMate, and full AI customization with dedicated data scientists for DataWiz.\",\n",
    "    \"MadeUpCompany's sustainability value focuses on ensuring their infrastructure is energy-efficient and environmentally responsible.\",\n",
    "    \"MadeUpCompany's mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.\"\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Answer is correct and more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Answer is correct and more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1/25 [00:13<05:16, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches CloudMate features' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches CloudMate features' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/25 [00:28<05:36, 14.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Mentions business continuity' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Exact match found' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Exact match found' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Matches expected content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Matches expected content' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 3/25 [00:41<05:03, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Extra information about plan positioning' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Similar content, more detail' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Similar content, more detail' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 4/25 [00:53<04:36, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsourced information' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 5/25 [01:04<04:06, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 6/25 [01:15<03:43, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No extra information' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 7/25 [01:26<03:30, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [01:39<03:21, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No hallucinations found' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [01:51<03:10, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same content' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [02:01<02:53, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Minor rephrasing' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [02:15<02:52, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [02:27<02:36, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added unsupplied plan context' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [02:38<02:20, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [02:49<02:08, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer fully supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is accurate' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is accurate' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [03:00<01:53, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [03:11<01:40, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [03:24<01:34, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [03:39<01:29, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Adds interpretation of plan suitability' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches email support guarantee' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches email support guarantee' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [03:54<01:20, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added resolution time detail' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [04:08<01:07, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Some details not supported' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact is fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact is fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [04:20<00:52, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Minor expansion of existing info' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='No trend forecasting mentioned' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='No trend forecasting mentioned' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is incorrect' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is incorrect' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [04:32<00:38, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No new info introduced' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Only flexible pricing mentioned' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Only flexible pricing mentioned' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer lacks specific details' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer lacks specific details' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [04:47<00:26, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer admits lack of knowledge' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [04:58<00:12, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added prioritizing detail' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [05:12<00:00, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'retrieval_quality': 0.92, 'answer_correctness': 0.92, 'hallucination': 0.24}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = evaluate_rag_system(\n",
    "    graph, \n",
    "    sample_queries,\n",
    "    expected_responses,\n",
    "    evaluator=RAGEvaluator(llm_func=call_judge),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "results[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores(scores):\n",
    "    \"\"\"\n",
    "    Plot the evaluation scores.\n",
    "    \"\"\"\n",
    "    labels = [\"Retrieval Quality\", \"Answer Correctness\", \"Hallucination\"]\n",
    "    scores = [scores[\"retrieval_quality\"], scores[\"answer_correctness\"], scores[\"hallucination\"]]\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    ax.bar(labels, scores)\n",
    "    ax.set_xlabel('Metric')\n",
    "    # set y range to 0-1\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('RAG Evaluation Scores')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(results[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'When was MadeUpCompany founded and where is it headquartered?',\n",
       "  'retrieved_context': [Document(id='4b2b4488-cd9e-451c-8835-583f9617a416', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='891efd52-009b-4d26-9d2a-1a844c114030', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='977eae9e-ef15-418d-9fbe-baedb032ee18', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany was founded in 2010 and its headquarters is located in San Francisco, California. The company also has satellite offices globally, including in cities like New York, London, and Tokyo. This information indicates both the founding year and location of the main office.',\n",
       "  'expected_answer': 'MadeUpCompany was founded in 2010 and is headquartered in San Francisco, California.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact matches documents',\n",
       "  'answer_correctness_reasoning': 'Answer is correct and more detailed',\n",
       "  'hallucination_reasoning': 'Answer is directly supported'},\n",
       " {'query': 'What security features does CloudMate offer for enterprise customers?',\n",
       "  'retrieved_context': [Document(id='0a1b807e-1725-40be-b713-92c5f03de150', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='309f4b50-a14a-41e2-b0c7-c19a5ff58b92', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='e8cac8f3-8b07-4805-806f-7bee6af9971c', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities')],\n",
       "  'generated_answer': ' \\nCloudMate offers several security features for enterprise customers, including military-grade encryption, multi-factor authentication, and role-based access control. These features provide a robust layer of protection against unauthorized access and ensure secure data management. Additionally, automated backups support business continuity in case of data loss or system failure.',\n",
       "  'expected_answer': 'CloudMate offers military-grade encryption, multi-factor authentication, and role-based access control for enterprise security.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 1,\n",
       "  'retrieval_quality_reasoning': 'Fact matches CloudMate features',\n",
       "  'answer_correctness_reasoning': 'Generated answer is more detailed',\n",
       "  'hallucination_reasoning': 'Mentions business continuity'},\n",
       " {'query': 'How much does the Professional plan for CloudMate cost and what storage capacity does it include?',\n",
       "  'retrieved_context': [Document(id='4f083b61-0624-41ff-9f75-6ec6afd5dd41', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='39446eb9-3b13-44c5-87a1-13dd84376c19', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='25ff5e3e-20be-4799-bdf0-b62583f31fd0', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager')],\n",
       "  'generated_answer': ' The Professional plan for CloudMate costs $29.99 per month and includes a storage capacity of 1TB. This plan also offers enhanced security and priority support. It sits between the basic and enterprise options in terms of price and included features.',\n",
       "  'expected_answer': 'The Professional plan for CloudMate costs $29.99/month and includes 1TB of storage, enhanced security, and priority support.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0.5,\n",
       "  'retrieval_quality_reasoning': 'Exact match found',\n",
       "  'answer_correctness_reasoning': 'Matches expected content',\n",
       "  'hallucination_reasoning': 'Extra information about plan positioning'},\n",
       " {'query': 'What analytics capabilities does DataWiz provide for business intelligence?',\n",
       "  'retrieved_context': [Document(id='ef7dd2e0-a44e-49a4-bb67-f36c484c83ba', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='9e94e54f-d669-439c-9ab1-e7a4dd3ac119', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='4e520c5c-2893-4a3b-a329-d438d01d89fb', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency')],\n",
       "  'generated_answer': \" \\nDataWiz provides various analytics capabilities including predictive analytics, real-time dashboards, API integrations, and automated anomaly detection. These features enable businesses to gain valuable insights from their data, facilitating informed decision-making. The platform's advanced data analytics transform raw data into actionable insights using cutting-edge machine learning models.\",\n",
       "  'expected_answer': 'DataWiz provides predictive analytics for demand forecasting and customer behavior modeling, real-time dashboards with customizable reporting, API integrations with popular business intelligence tools, and automated anomaly detection.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact fully present',\n",
       "  'answer_correctness_reasoning': 'Similar content, more detail',\n",
       "  'hallucination_reasoning': 'No unsourced information'},\n",
       " {'query': 'What compliance standards does MadeUpCompany adhere to?',\n",
       "  'retrieved_context': [Document(id='c6143988-259a-4677-93a0-b64b58a0be87', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='8068d6da-5972-47ba-aabc-817499e99c00', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='eef82762-9f04-48da-bd75-0355929c318b', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany adheres to several key compliance standards, specifically GDPR, HIPAA, and SOC 2 Compliance. These ensure global security and data protection compliance. The company also implements additional security measures such as end-to-end encryption and zero trust architecture.',\n",
       "  'expected_answer': 'MadeUpCompany adheres to GDPR, HIPAA, and SOC 2 compliance standards for global security and data protection compliance.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact mentioned in documents',\n",
       "  'answer_correctness_reasoning': 'More detailed than expected',\n",
       "  'hallucination_reasoning': 'Answer is directly supported'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"individual_results\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustement 1: Adjust top-k retrieval\n",
    "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Answer is correct and more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Answer is correct and more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1/25 [00:12<05:10, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No extra information' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches CloudMate features' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches CloudMate features' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/25 [00:23<04:21, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Mentions business continuity' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in all documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in all documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Matches expected content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Matches expected content' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 3/25 [00:35<04:17, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Extra information about plan position' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully described' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully described' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Similar content, more details' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Similar content, more details' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 4/25 [00:47<04:13, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact explicitly mentioned' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact explicitly mentioned' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 5/25 [00:59<03:58, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported information' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is accurate' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is accurate' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 6/25 [01:13<04:00, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 7/25 [01:24<03:34, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No extra info added' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [01:36<03:23, 11.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [01:48<03:10, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Matching values found' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Matching values found' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Fully correct with extra detail' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Fully correct with extra detail' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [02:04<03:18, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added operational detail' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [02:15<02:56, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by context' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches document info' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches document info' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [02:27<02:41, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Adds suitability information' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact stated in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [02:39<02:29, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer fully supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [02:51<02:13, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [03:02<01:59, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [03:14<01:47, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [03:26<01:34, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in all docs' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in all docs' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [03:36<01:19, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Mentions foundational level' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [03:47<01:06, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added resolution time' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [04:00<00:59, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added details on machine learning' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same content' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [04:11<00:46, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Partial information inferred' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='No trend forecasting mentioned' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='No trend forecasting mentioned' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Lacks specific information' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Lacks specific information' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [04:25<00:36, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No new info introduced' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Pricing plans mentioned, but details lacking' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Pricing plans mentioned, but details lacking' score=0.5\n",
      "[evaluation_answer_correctness] LLM response: reasoning='No relevant information provided' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='No relevant information provided' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [04:56<00:35, 17.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer states lack of knowledge' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches company values' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches company values' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [05:20<00:19, 19.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added unsubstantiated environmental impact' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [05:32<00:00, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer restates mission' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'retrieval_quality': 0.94, 'answer_correctness': 0.92, 'hallucination': 0.3}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = evaluate_rag_system(\n",
    "    graph, \n",
    "    sample_queries,\n",
    "    expected_responses,\n",
    "    evaluator=RAGEvaluator(llm_func=call_judge),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "results[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQoJJREFUeJzt3XlUVfX+//HXiVkQHEAcQsQcwkj7ilZSBg7hlJl1b6iVE97CIVOsruZ1zCIrTe06lfNNEys1ZyVNHDBTkwYlc8ZueM1ZUxHh8/vDxfl1BBQVPbh7PtY6a3k++7P3fm/cZ/Pis4djM8YYAQAAWMRdzi4AAACgKBFuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBuAACApRBugFtoxowZstls9perq6sqVKigdu3aaffu3QXON27cONlsNoWFhV11+fv371fv3r0VGhoqb29veXp6qkqVKnr++ef19ddf61oPID9w4IBDfVe+hg4deiObXShDhw6VzWa7ZcuXpHPnzmno0KFau3Ztnmm5/zcHDhy4pTXkJysrS5MnT1b9+vVVpkwZlShRQsHBwWrTpo0WLFhw2+sBrMbV2QUAfwXTp0/XvffeqwsXLmjjxo1666239PXXX+vnn39W6dKl8/SfNm2aJGnHjh3avHmzHnrooTx9Fi1apA4dOsjf319xcXGqW7euPDw8tGfPHn3++edq3LixvvrqKzVp0uSa9b388svq0KFDnva77777Bra2+Dh37pyGDRsmSYqKinKY1qpVK23atEkVKlS47XW98MILmj9/vvr06aNhw4bJw8ND+/bt04oVK7Ry5Uq1bdv2ttcEWAnhBrgNwsLCVK9ePUmXf8lmZ2dryJAhWrhwobp06eLQd+vWrfr+++/VqlUrLV26VFOnTs0Tbvbu3av27dvrvvvu01dffSVfX1/7tMjISMXGxmrt2rX5Bqf8VK5cWQ8//PBNbuWdJSAgQAEBAbd9vfv371diYqIGDx5sD16S1KRJE/3jH/9QTk7ObavFGKMLFy7Iy8vrtq0TuB04LQU4QW7Q+d///pdn2tSpUyVJ77zzjiIiIjR37lydO3fOoc/o0aN17tw5TZgwwSHY/FlUVJTq1KlTJPX26dNH3t7eOn36dJ5pMTExCgwMVFZWliQpMTFR0dHRqlChgry8vBQaGqr+/fvrjz/+uOZ6CjoVVqVKFXXu3Nn+/vfff1ePHj1Uq1Yt+fj4qFy5cmrcuLHWr19v73PgwAF7eBk2bJj9VFvucgo6LTVt2jTVqVNHnp6eKlOmjNq2bau0tDSHPp07d5aPj4/27Nmjli1bysfHR0FBQerXr58yMzOvuo3Hjh2TpAJHjO66y/GwfPLkSfXr109Vq1aVh4eHypUrp5YtW+rnn3+29zl+/Lh69OihSpUqyd3dXVWrVtXAgQPz1GKz2dSrVy9NmjRJoaGh8vDw0MyZMyVJu3fvVocOHVSuXDl5eHgoNDRU48ePd5g/JydHI0aMUM2aNeXl5aVSpUqpdu3aGjt27FW3GbjdCDeAE+zfv1+SVKNGDYf28+fP69NPP1X9+vUVFhamrl276syZM/rss88c+iUlJalChQr2kHSzcnJydOnSpTyvXF27dtW5c+c0b948h/lOnjypL7/8Us8//7zc3NwkXf4l2bJlS02dOlUrVqxQnz59NG/ePLVu3bpIapUu/zKXpCFDhmjp0qWaPn26qlatqqioKPv1NRUqVNCKFSskSbGxsdq0aZM2bdqkQYMGFbjchIQExcbG6r777tP8+fM1duxY/fDDD2rQoEGea6SysrL05JNPqkmTJvryyy/VtWtXffDBBxo5cuRVaw8NDVWpUqU0bNgwffTRR1e95ufMmTN69NFHNXnyZHXp0kWLFy/WpEmTVKNGDWVkZEiSLly4oEaNGmnWrFmKj4/X0qVL9fzzz+vdd9/V008/nWeZCxcu1MSJEzV48GCtXLlSDRs21M6dO1W/fn399NNPGjVqlJYsWaJWrVqpd+/eDqNL7777roYOHar27dtr6dKlSkxMVGxsrE6ePHnVbQZuOwPglpk+fbqRZL755huTlZVlzpw5Y1asWGHKly9vHnvsMZOVleXQf9asWUaSmTRpkjHGmDNnzhgfHx/TsGFDh36enp7m4YcfzrO+7Oxsk5WVZX9lZ2dftb79+/cbSQW+1q9fb+9bt25dExER4TD/hAkTjCTz448/5rv8nJwck5WVZZKTk40k8/3339unDRkyxFx5CJJkhgwZkmc5wcHBplOnTgVux6VLl0xWVpZp0qSJadu2rb39999/L3CZuf83+/fvN8YYc+LECePl5WVatmzp0C89Pd14eHiYDh062Ns6depkJJl58+Y59G3ZsqWpWbNmgXXmWrp0qfH397f/nMuWLWv+/ve/m0WLFjn0Gz58uJFkkpKSClzWpEmT8q1l5MiRRpJZtWqVvU2S8fPzM8ePH3fo26xZM3P33XebU6dOObT36tXLeHp62vs/8cQT5oEHHrjm9gHOxsgNcBs8/PDDcnNzU8mSJdW8eXOVLl1aX375pVxdHS97mzp1qry8vNSuXTtJko+Pj/7+979r/fr1V727KtfTTz8tNzc3+6t3796Fqu+VV17Rli1b8rweeOABe58uXbooJSVFu3btsrdNnz7dPsqUa9++ferQoYPKly8vFxcXubm5KTIyUpLynN65GZMmTVLdunXl6ekpV1dXubm5afXq1Te8jk2bNun8+fMOp78kKSgoSI0bN9bq1asd2m02W57RqNq1a+vgwYPXXFfLli2Vnp6uBQsW6NVXX9V9992nhQsX6sknn1SvXr3s/ZYvX64aNWqoadOmBS5rzZo18vb21t/+9jeH9tztuLLuxo0bO1yLdeHCBa1evVpt27ZViRIlHEbuWrZsqQsXLuibb76RJD344IP6/vvv1aNHD61cuTLf05RAcUC4AW6DWbNmacuWLVqzZo1eeuklpaWlqX379g599uzZo3Xr1qlVq1YyxujkyZM6efKk/ZdW7h1U0uULgPP7JTpq1Ch7MLked999t+rVq5fn5ePjY+/z3HPPycPDQzNmzJAk7dy5U1u2bHG4IPrs2bNq2LChNm/erBEjRmjt2rXasmWL5s+fL+nyabeiMHr0aHXv3l0PPfSQvvjiC33zzTfasmWLmjdvfsPruNq1MBUrVrRPz1WiRAl5eno6tHl4eOjChQuFWp+Xl5eeeuopvffee0pOTtaePXtUq1YtjR8/Xjt27JB0+dqia92xduzYMZUvXz7PbfXlypWTq6trnrqv3L5jx47p0qVL+vDDDx2CsZubm1q2bClJOnr0qCRpwIABev/99/XNN9+oRYsWKlu2rJo0aaKtW7cWapuB24W7pYDbIDQ01H59TKNGjZSdna0pU6bo888/dwgvxhh9/vnn+vzzz/MsY+bMmRoxYoRcXFz0+OOPa/z48dq6davDdTf33HPPLduG0qVLq02bNpo1a5ZGjBih6dOny9PT0yGkrVmzRr/99pvWrl1rH62RVOhrMjw8PPK9IPfKX9CffPKJoqKiNHHiRIf2M2fOXMcWOSpbtqwk2a9l+bPffvtN/v7+N7zswqhcubJefPFF9enTRzt27NB9992ngIAA/frrr1edr2zZstq8ebOMMQ4B58iRI7p06VKeuq8MQaVLl5aLi4teeOEF9ezZM991hISESJJcXV0VHx+v+Ph4nTx5Ul999ZXeeOMNNWvWTIcOHVKJEiVuZNOBIsfIDeAE7777rkqXLq3BgwcrJydH2dnZmjlzpu655x59/fXXeV79+vVTRkaGli9fLknq27evSpQooZ49e97UL/Tr1aVLF/32229atmyZPvnkE7Vt21alSpWyT8/9xenh4eEw3+TJkwu1/CpVquiHH35waFuzZo3Onj3r0Gaz2fKs44cfftCmTZsc2nL7FGY0p0GDBvLy8tInn3zi0P7rr79qzZo1hXpeUGGcOXMmz/bkyj2lVrFiRUlSixYt9Msvv2jNmjUFLq9JkyY6e/asFi5c6NA+a9Ys+/SrKVGihBo1aqTt27erdu3a+Y7g5Qa/PytVqpT+9re/qWfPnjp+/LhTHoYIFISRG8AJSpcurQEDBuj111/XnDlzVKpUKf32228aOXJknofNSZefk/Pvf/9bU6dO1RNPPKF77rlHn376qdq3b6/7779f3bt3tz/E78iRI1q1apUkFXib+JXS09Pt11X8WUBAgMNoUHR0tO6++2716NFDhw8fzvOMnoiICJUuXVpxcXEaMmSI3NzcNHv2bH3//feFquOFF17QoEGDNHjwYEVGRmrnzp3697//LT8/P4d+TzzxhN58800NGTJEkZGR2rVrl4YPH66QkBCHu7xKliyp4OBgffnll2rSpInKlCkjf39/ValSJc+6S5UqpUGDBumNN95Qx44d1b59ex07dkzDhg2Tp6enhgwZUqhtuJZdu3apWbNmateunSIjI1WhQgWdOHFCS5cu1UcffaSoqChFRERIunwLfmJiotq0aaP+/fvrwQcf1Pnz55WcnKwnnnhCjRo1UseOHTV+/Hh16tRJBw4c0P33368NGzbo7bffVsuWLa96vU6usWPH6tFHH1XDhg3VvXt3ValSRWfOnNGePXu0ePFie7hq3bq1/ZlNAQEBOnjwoMaMGaPg4GBVr169SH4+QJFw8gXNgKXl3pGzZcuWPNPOnz9vKleubKpXr26eeuop4+7ubo4cOVLgstq1a2dcXV3N4cOH7W179+41L7/8sqlZs6bx8vIyHh4eJjg42Pz97383CxYsMDk5OVet71p3Sz333HN55nnjjTeMJBMUFJTv3VgpKSmmQYMGpkSJEiYgIMB069bNfPfdd0aSmT59ur1ffndLZWZmmtdff90EBQUZLy8vExkZaVJTU/PcLZWZmWleffVVU6lSJePp6Wnq1q1rFi5caDp16mSCg4MdlvnVV1+Z//u//zMeHh5Gkn05V94tlWvKlCmmdu3axt3d3fj5+Zk2bdqYHTt2OPTp1KmT8fb2zrPt+W3TlU6cOGFGjBhhGjdubCpVqmTc3d2Nt7e3eeCBB8yIESPMuXPn8vR/5ZVXTOXKlY2bm5spV66cadWqlfn555/tfY4dO2bi4uJMhQoVjKurqwkODjYDBgwwFy5ccFiWJNOzZ89869q/f7/p2rWrqVSpknFzczMBAQEmIiLCjBgxwt5n1KhRJiIiwvj7+xt3d3dTuXJlExsbaw4cOHDVbQZuN5sx1/jyGQAAgDsI19wAAABLIdwAAABLIdwAAABLcWq4WbdunVq3bq2KFSvKZrPluZUxP8nJyQoPD5enp6eqVq2qSZMm3fpCAQDAHcOp4eaPP/5QnTp19O9//7tQ/ffv36+WLVuqYcOG2r59u9544w317t1bX3zxxS2uFAAA3CmKzd1SNptNCxYs0FNPPVVgn3/+859atGiRw3fHxMXF6fvvv8/z8C4AAPDXdEc9xG/Tpk2Kjo52aGvWrJmmTp2qrKwsubm55ZknMzPT4XHuOTk5On78uMqWLZvnMeQAAKB4MsbozJkzqlixou666+onnu6ocHP48GEFBgY6tAUGBurSpUs6evRovl94l5CQoGHDht2uEgEAwC106NCha36h7B0VbqS8X/qWe1atoFGYAQMGKD4+3v7+1KlTqly5sg4dOlToR9MDAADnOn36tIKCglSyZMlr9r2jwk358uV1+PBhh7YjR47I1dU13y92ky5/cd6VX7AnXf7OHcINAAB3lsJcUnJHPeemQYMGSkpKcmhbtWqV6tWrl+/1NgAA4K/HqeHm7NmzSk1NVWpqqqTLt3qnpqYqPT1d0uVTSh07drT3j4uL08GDBxUfH6+0tDRNmzZNU6dO1auvvuqM8gEAQDHk1NNSW7duVaNGjezvc6+N6dSpk2bMmKGMjAx70JGkkJAQLVu2TH379tX48eNVsWJFjRs3Ts8888xtrx0AABRPxeY5N7fL6dOn5efnp1OnTnHNDQAAd4jr+f19R11zAwAAcC2EGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmEGwAAYCmuzi7Aaqr0X+rsEuBkB95p5ewSAOAvjZEbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKYQbAABgKTznBrAYnrUEnrWEvzpGbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKUQbgAAgKU4PdxMmDBBISEh8vT0VHh4uNavX3/V/rNnz1adOnVUokQJVahQQV26dNGxY8duU7UAAKC4c2q4SUxMVJ8+fTRw4EBt375dDRs2VIsWLZSenp5v/w0bNqhjx46KjY3Vjh079Nlnn2nLli3q1q3bba4cAAAUV04NN6NHj1ZsbKy6deum0NBQjRkzRkFBQZo4cWK+/b/55htVqVJFvXv3VkhIiB599FG99NJL2rp1622uHAAAFFdOCzcXL17Utm3bFB0d7dAeHR2tlJSUfOeJiIjQr7/+qmXLlskYo//973/6/PPP1apVqwLXk5mZqdOnTzu8AACAdTkt3Bw9elTZ2dkKDAx0aA8MDNThw4fznSciIkKzZ89WTEyM3N3dVb58eZUqVUoffvhhgetJSEiQn5+f/RUUFFSk2wEAAIoXp19QbLPZHN4bY/K05dq5c6d69+6twYMHa9u2bVqxYoX279+vuLi4Apc/YMAAnTp1yv46dOhQkdYPAACKF1dnrdjf318uLi55RmmOHDmSZzQnV0JCgh555BG99tprkqTatWvL29tbDRs21IgRI1ShQoU883h4eMjDw6PoNwAAABRLThu5cXd3V3h4uJKSkhzak5KSFBERke88586d0113OZbs4uIi6fKIDwAAgFNPS8XHx2vKlCmaNm2a0tLS1LdvX6Wnp9tPMw0YMEAdO3a092/durXmz5+viRMnat++fdq4caN69+6tBx98UBUrVnTWZgAAgGLEaaelJCkmJkbHjh3T8OHDlZGRobCwMC1btkzBwcGSpIyMDIdn3nTu3FlnzpzRv//9b/Xr10+lSpVS48aNNXLkSGdtAgAAKGZs5i92Puf06dPy8/PTqVOn5OvrW+TLr9J/aZEvE3eWA+8U/GiC24F9EM7eB4Fb4Xp+fzv9bikAAICiRLgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACWQrgBAACW4vRwM2HCBIWEhMjT01Ph4eFav379VftnZmZq4MCBCg4OloeHh+655x5NmzbtNlULAACKO1dnrjwxMVF9+vTRhAkT9Mgjj2jy5Mlq0aKFdu7cqcqVK+c7z7PPPqv//e9/mjp1qqpVq6YjR47o0qVLt7lyAABQXDk13IwePVqxsbHq1q2bJGnMmDFauXKlJk6cqISEhDz9V6xYoeTkZO3bt09lypSRJFWpUuV2lgwAAIo5p52WunjxorZt26bo6GiH9ujoaKWkpOQ7z6JFi1SvXj29++67qlSpkmrUqKFXX31V58+fL3A9mZmZOn36tMMLAABYl9NGbo4ePars7GwFBgY6tAcGBurw4cP5zrNv3z5t2LBBnp6eWrBggY4ePaoePXro+PHjBV53k5CQoGHDhhV5/QAAoHhy+gXFNpvN4b0xJk9brpycHNlsNs2ePVsPPvigWrZsqdGjR2vGjBkFjt4MGDBAp06dsr8OHTpU5NsAAACKD6eN3Pj7+8vFxSXPKM2RI0fyjObkqlChgipVqiQ/Pz97W2hoqIwx+vXXX1W9evU883h4eMjDw6NoiwcAAMWW00Zu3N3dFR4erqSkJIf2pKQkRURE5DvPI488ot9++01nz561t/3yyy+66667dPfdd9/SegEAwJ3Bqael4uPjNWXKFE2bNk1paWnq27ev0tPTFRcXJ+nyKaWOHTva+3fo0EFly5ZVly5dtHPnTq1bt06vvfaaunbtKi8vL2dtBgAAKEaceit4TEyMjh07puHDhysjI0NhYWFatmyZgoODJUkZGRlKT0+39/fx8VFSUpJefvll1atXT2XLltWzzz6rESNGOGsTAABAMePUcCNJPXr0UI8ePfKdNmPGjDxt9957b55TWQAAALmcfrcUAABAUSLcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAASyHcAAAAS7mpcHPx4kXt2rVLly5dKqp6AAAAbsoNhZtz584pNjZWJUqU0H333af09HRJUu/evfXOO+8UaYEAAADX44bCzYABA/T9999r7dq18vT0tLc3bdpUiYmJRVYcAADA9XK9kZkWLlyoxMREPfzww7LZbPb2WrVqae/evUVWHAAAwPW6oZGb33//XeXKlcvT/scffziEHQAAgNvthsJN/fr1tXTpUvv73EDz8ccfq0GDBkVTGQAAwA24odNSCQkJat68uXbu3KlLly5p7Nix2rFjhzZt2qTk5OSirhEAAKDQbmjkJiIiQikpKTp37pzuuecerVq1SoGBgdq0aZPCw8OLukYAAIBCu+6Rm6ysLL344osaNGiQZs6ceStqAgAAuGHXPXLj5uamBQsW3IpaAAAAbtoNnZZq27atFi5cWMSlAAAA3LwbuqC4WrVqevPNN5WSkqLw8HB5e3s7TO/du3eRFAcAAHC9bijcTJkyRaVKldK2bdu0bds2h2k2m41wAwAAnOaGws3+/fuLug4AAIAicVPfCi5JxhgZY4qiFgAAgJt2w+Fm1qxZuv/+++Xl5SUvLy/Vrl1b//nPf4qyNgAAgOt2Q6elRo8erUGDBqlXr1565JFHZIzRxo0bFRcXp6NHj6pv375FXScAAECh3FC4+fDDDzVx4kR17NjR3tamTRvdd999Gjp0KOEGAAA4zQ2dlsrIyFBERESe9oiICGVkZNx0UQAAADfqhsJNtWrVNG/evDztiYmJql69+k0XBQAAcKNu6LTUsGHDFBMTo3Xr1umRRx6RzWbThg0btHr16nxDDwAAwO1yQyM3zzzzjDZv3ix/f38tXLhQ8+fPl7+/v7799lu1bdu2qGsEAAAotBsauZGk8PBwffLJJ0VZCwAAwE27oZGbZcuWaeXKlXnaV65cqeXLl990UQAAADfqhsJN//79lZ2dnafdGKP+/fvfdFEAAAA36obCze7du1WrVq087ffee6/27Nlz00UBAADcqBsKN35+ftq3b1+e9j179sjb2/umiwIAALhRNxRunnzySfXp00d79+61t+3Zs0f9+vXTk08+WWTFAQAAXK8bCjfvvfeevL29de+99yokJEQhISG69957VbZsWb3//vtFXSMAAECh3dCt4H5+fkpJSVFSUpK+//57eXl5qU6dOmrYsGFR1wcAAHBdrmvkZvPmzfZbvW02m6Kjo1WuXDm9//77euaZZ/Tiiy8qMzPzlhQKAABQGNcVboYOHaoffvjB/v7HH3/UP/7xDz3++OPq37+/Fi9erISEhCIvEgAAoLCuK9ykpqaqSZMm9vdz587Vgw8+qI8//ljx8fEaN24c3y0FAACc6rrCzYkTJxQYGGh/n5ycrObNm9vf169fX4cOHSq66gAAAK7TdYWbwMBA7d+/X5J08eJFfffdd2rQoIF9+pkzZ+Tm5la0FQIAAFyH6wo3zZs3V//+/bV+/XoNGDBAJUqUcLhD6ocfftA999xT5EUCAAAU1nXdCj5ixAg9/fTTioyMlI+Pj2bOnCl3d3f79GnTpik6OrrIiwQAACis6wo3AQEBWr9+vU6dOiUfHx+5uLg4TP/ss8/k4+NTpAUCAABcjxt+iF9+ypQpc1PFAAAA3Kwb+voFAACA4opwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALIVwAwAALMXp4WbChAkKCQmRp6enwsPDtX79+kLNt3HjRrm6uuqBBx64tQUCAIA7ilPDTWJiovr06aOBAwdq+/btatiwoVq0aKH09PSrznfq1Cl17NhRTZo0uU2VAgCAO4VTw83o0aMVGxurbt26KTQ0VGPGjFFQUJAmTpx41fleeukldejQQQ0aNLhNlQIAgDuF08LNxYsXtW3bNkVHRzu0R0dHKyUlpcD5pk+frr1792rIkCGFWk9mZqZOnz7t8AIAANbltHBz9OhRZWdnKzAw0KE9MDBQhw8fznee3bt3q3///po9e7ZcXV0LtZ6EhAT5+fnZX0FBQTddOwAAKL6cfkGxzWZzeG+MydMmSdnZ2erQoYOGDRumGjVqFHr5AwYM0KlTp+yvQ4cO3XTNAACg+Crc8Mct4O/vLxcXlzyjNEeOHMkzmiNJZ86c0datW7V9+3b16tVLkpSTkyNjjFxdXbVq1So1btw4z3weHh7y8PC4NRsBAACKHaeN3Li7uys8PFxJSUkO7UlJSYqIiMjT39fXVz/++KNSU1Ptr7i4ONWsWVOpqal66KGHblfpAACgGHPayI0kxcfH64UXXlC9evXUoEEDffTRR0pPT1dcXJyky6eU/vvf/2rWrFm66667FBYW5jB/uXLl5OnpmacdAAD8dTk13MTExOjYsWMaPny4MjIyFBYWpmXLlik4OFiSlJGRcc1n3gAAAPyZzRhjnF3E7XT69Gn5+fnp1KlT8vX1LfLlV+m/tMiXiTvLgXdaOXX97INw9j4I3ArX8/vb6XdLAQAAFCXCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBTCDQAAsBRXZxcAALCWKv2XOrsEONmBd1o5df2M3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEsh3AAAAEtxeriZMGGCQkJC5OnpqfDwcK1fv77AvvPnz9fjjz+ugIAA+fr6qkGDBlq5cuVtrBYAABR3Tg03iYmJ6tOnjwYOHKjt27erYcOGatGihdLT0/Ptv27dOj3++ONatmyZtm3bpkaNGql169bavn37ba4cAAAUV04NN6NHj1ZsbKy6deum0NBQjRkzRkFBQZo4cWK+/ceMGaPXX39d9evXV/Xq1fX222+revXqWrx48W2uHAAAFFdOCzcXL17Utm3bFB0d7dAeHR2tlJSUQi0jJydHZ86cUZkyZQrsk5mZqdOnTzu8AACAdTkt3Bw9elTZ2dkKDAx0aA8MDNThw4cLtYxRo0bpjz/+0LPPPltgn4SEBPn5+dlfQUFBN1U3AAAo3px+QbHNZnN4b4zJ05afTz/9VEOHDlViYqLKlStXYL8BAwbo1KlT9tehQ4duumYAAFB8uTprxf7+/nJxcckzSnPkyJE8ozlXSkxMVGxsrD777DM1bdr0qn09PDzk4eFx0/UCAIA7g9NGbtzd3RUeHq6kpCSH9qSkJEVERBQ436effqrOnTtrzpw5atWq1a0uEwAA3GGcNnIjSfHx8XrhhRdUr149NWjQQB999JHS09MVFxcn6fIppf/+97+aNWuWpMvBpmPHjho7dqwefvhh+6iPl5eX/Pz8nLYdAACg+HBquImJidGxY8c0fPhwZWRkKCwsTMuWLVNwcLAkKSMjw+GZN5MnT9alS5fUs2dP9ezZ097eqVMnzZgx43aXDwAAiiGnhhtJ6tGjh3r06JHvtCsDy9q1a299QQAA4I7m9LulAAAAihLhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWArhBgAAWIrTw82ECRMUEhIiT09PhYeHa/369Vftn5ycrPDwcHl6eqpq1aqaNGnSbaoUAADcCZwabhITE9WnTx8NHDhQ27dvV8OGDdWiRQulp6fn23///v1q2bKlGjZsqO3bt+uNN95Q79699cUXX9zmygEAQHHl1HAzevRoxcbGqlu3bgoNDdWYMWMUFBSkiRMn5tt/0qRJqly5ssaMGaPQ0FB169ZNXbt21fvvv3+bKwcAAMWV08LNxYsXtW3bNkVHRzu0R0dHKyUlJd95Nm3alKd/s2bNtHXrVmVlZd2yWgEAwJ3D1VkrPnr0qLKzsxUYGOjQHhgYqMOHD+c7z+HDh/Ptf+nSJR09elQVKlTIM09mZqYyMzPt70+dOiVJOn369M1uQr5yMs/dkuXiznGr9q3CYh8E+yCc7Vbsg7nLNMZcs6/Twk0um83m8N4Yk6ftWv3za8+VkJCgYcOG5WkPCgq63lKBQvEb4+wK8FfHPghnu5X74JkzZ+Tn53fVPk4LN/7+/nJxcckzSnPkyJE8ozO5ypcvn29/V1dXlS1bNt95BgwYoPj4ePv7nJwcHT9+XGXLlr1qiML1O336tIKCgnTo0CH5+vo6uxz8BbEPwtnYB28dY4zOnDmjihUrXrOv08KNu7u7wsPDlZSUpLZt29rbk5KS1KZNm3znadCggRYvXuzQtmrVKtWrV09ubm75zuPh4SEPDw+HtlKlSt1c8bgqX19fPtRwKvZBOBv74K1xrRGbXE69Wyo+Pl5TpkzRtGnTlJaWpr59+yo9PV1xcXGSLo+6dOzY0d4/Li5OBw8eVHx8vNLS0jRt2jRNnTpVr776qrM2AQAAFDNOveYmJiZGx44d0/Dhw5WRkaGwsDAtW7ZMwcHBkqSMjAyHZ96EhIRo2bJl6tu3r8aPH6+KFStq3LhxeuaZZ5y1CQAAoJixmcJcdgwUQmZmphISEjRgwIA8pwKB24F9EM7GPlg8EG4AAIClOP27pQAAAIoS4QYAAFgK4QYAAFgK4cbiqlSpojFjxtzWdXbu3FlPPfXUbV3n1Rw4cEA2m02pqamSpLVr18pms+nkyZNOrQvA7RUVFaU+ffrY3xf18fF2HvuccWy/kxBubqPOnTvLZrPJZrPJ1dVVlStXVvfu3XXixIlCL+PKX9TXsmXLFr344os3WPGtk52drQ8++EC1a9eWp6enSpUqpRYtWmjjxo23fN0RERHKyMiwPwxqxowZlnmwY0pKilxcXNS8eXNnl1KkjDH66KOP9NBDD8nHx0elSpVSvXr1NGbMGJ07Vzy/x8hms2nhwoXOLsMSCgoNxe0PlbFjx2rGjBlFusyCjk/F9dheXBBubrPmzZsrIyNDBw4c0JQpU7R48WL16NGjyNdz8eJFSVJAQIBKlChR5Mu/GcYYtWvXTsOHD1fv3r2Vlpam5ORkBQUFKSoq6pb/QnB3d1f58uUt+fUb06ZN08svv6wNGzY4PCPqTpCVlVXgtBdeeEF9+vRRmzZt9PXXXys1NVWDBg3Sl19+qVWrVhXpOnM/O8D18vPzu21/KBXHY3uxYnDbdOrUybRp08ahLT4+3pQpU8ahbdq0aebee+81Hh4epmbNmmb8+PH2aZIcXpGRkQ7Lfvvtt02FChVMcHCwMcaY4OBg88EHH9jnP3nypPnHP/5hAgICTMmSJU2jRo1MamqqMcaYn3/+2UgyaWlpDvWMGjXKBAcHm5ycHHPp0iXTtWtXU6VKFePp6Wlq1KhhxowZc83t/LO5c+caSWbRokV5pj399NOmbNmy5uzZswUu65VXXrFvtzHGLF++3DzyyCPGz8/PlClTxrRq1crs2bPHPn3//v1Gktm+fbsxxpivv/7aSDInTpyw//vPryFDhphhw4aZsLCwPPXVrVvXDBo0qMBtc6azZ8+akiVLmp9//tnExMSYYcOGOUzP3davvvrKhIeHGy8vL9OgQQPz888/2/ukpqaaqKgo4+PjY0qWLGnq1q1rtmzZYnJycoy/v7/5/PPP7X3r1KljAgIC7O9TUlKMq6urOXPmjDHm6vuaMcYMGTLE1KlTx0ydOtWEhIQYm81mcnJy8mxXYmKikWQWLlyYZ1pOTo45efKkMcaY7OxsM2zYMFOpUiXj7u5u6tSpY5YvX27vm7sfJCYmmsjISOPh4WGmTZtW4Gfn119/Nc8++6wpVaqUKVOmjHnyySfN/v37HdY/depUU6tWLePu7m7Kly9vevbsaYy5/Ln78z6Vu8zcbZ41a5YJDg42vr6+JiYmxpw+fdphm0aOHGlCQkKMp6enqV27tvnss8/s048fP246dOhg/P39jaenp6lWrZqZNm2aMcaYzMxM07NnT1O+fHnj4eFhgoODzdtvv53n53anKeiY8ufP8tGjR027du1MpUqVjJeXlwkLCzNz5sxx6B8ZGWleeeUV+/s/Hx+vPE4YY8yJEyeMJPP111/b23766SfTsmVLU7JkSePj42MeffRR+/HmyjojIyPNyy+/bF577TVTunRpExgYaIYMGeJQ06hRo0xYWJgpUaKEufvuu0337t3tn6GCjk9X1m6MMQcPHjRPPvmk8fb2NiVLljR///vfzeHDh+3TC7PvWQkjN060b98+rVixwuF7sT7++GMNHDhQb731ltLS0vT2229r0KBBmjlzpiTp22+/lSR99dVXysjI0Pz58+3zrl69WmlpaUpKStKSJUvyrM8Yo1atWunw4cNatmyZtm3bprp166pJkyY6fvy4atasqfDwcM2ePdthvjlz5qhDhw6y2WzKycnR3XffrXnz5mnnzp0aPHiw3njjDc2bN6/Q2z1nzhzVqFFDrVu3zjOtX79+OnbsmJKSkgq9vD/++EPx8fHasmWLVq9erbvuuktt27ZVTk7ONeeNiIjQmDFj5Ovrq4yMDGVkZOjVV19V165dtXPnTm3ZssXe94cfftD27dvVuXPnQtd2OyUmJqpmzZqqWbOmnn/+eU2fPl0mn8dYDRw4UKNGjdLWrVvl6uqqrl272qc999xzuvvuu7VlyxZt27ZN/fv3l5ubm2w2mx577DGtXbtWknTixAnt3LlTWVlZ2rlzp6TLpwjCw8Pl4+NzzX0t1549ezRv3jx98cUXBZ5qnT17tmrWrJnvd87ZbDb76cWxY8dq1KhRev/99/XDDz+oWbNmevLJJ7V7926Hef75z3/aRwybNWsmKe9n59y5c2rUqJF8fHy0bt06bdiwQT4+PmrevLl9ZGfixInq2bOnXnzxRf34449atGiRqlWrJkn2/Wb69OnKyMhw2I/27t2rhQsXasmSJVqyZImSk5P1zjvv2Kf/61//0vTp0zVx4kTt2LFDffv21fPPP6/k5GRJ0qBBg7Rz504tX75caWlpmjhxovz9/SVJ48aN06JFizRv3jzt2rVLn3zyiapUqZLvz9VqLly4oPDwcC1ZskQ//fSTXnzxRb3wwgvavHlzka3jv//9rx577DF5enpqzZo12rZtm7p27apLly4VOM/MmTPl7e2tzZs3691339Xw4cMdjm933XWXxo0bp59++kkzZ87UmjVr9Prrr0sq+Ph0JWOMnnrqKR0/flzJyclKSkrS3r17FRMT49DvWvuepTg3W/21dOrUybi4uBhvb2/j6elpT+KjR4+29wkKCsrz18abb75pGjRoYIzJ/6+L3GUHBgaazMxMh/Y/p/vVq1cbX19fc+HCBYc+99xzj5k8ebIxxpjRo0ebqlWr2qft2rXLSDI7duwocLt69OhhnnnmGYdarjZyc++99xY4/fjx40aSGTlyZIHLunLk5kpHjhwxksyPP/5ojLn6yI0xxkyfPt34+fnlWU6LFi1M9+7d7e/79OljoqKiClyvs0VERNhH0bKysoy/v79JSkqyT//zyE2upUuXGknm/PnzxhhjSpYsaWbMmJHv8seNG2cfzVq4cKGpV6+eefrpp+0ji9HR0eaf//ynMaZw+9qQIUOMm5ubOXLkyFW3KzQ01Dz55JPX3P6KFSuat956y6Gtfv36pkePHsaY/78f5DfSeOVnZ+rUqaZmzZoOI0mZmZnGy8vLrFy50r6+gQMHFliPJLNgwQKHtiFDhpgSJUo4/LX82muvmYceesgYc3n0zdPT06SkpDjMFxsba9q3b2+MMaZ169amS5cu+a7z5ZdfNo0bN853BOxO9udj559fucfR3M/ylVq2bGn69etnf3+zIzcDBgwwISEh5uLFiwXWeeXIzaOPPurQp379+vbPSX7mzZtnypYta39f0PHpz7WvWrXKuLi4mPT0dPv0HTt2GEnm22+/NcZce9+zGkZubrNGjRopNTVVmzdv1ssvv6xmzZrp5ZdfliT9/vvvOnTokGJjY+Xj42N/jRgxQnv37r3msu+//365u7sXOH3btm06e/asypYt67D8/fv325ffrl07HTx4UN98842ky381P/DAA6pVq5Z9OZMmTVK9evUUEBAgHx8fffzxx0V+fcfVtuNKe/fuVYcOHVS1alX5+voqJCREkm66pn/84x/69NNPdeHCBWVlZWn27NkOoxzFya5du/Ttt9+qXbt2kiRXV1fFxMRo2rRpefrWrl3b/u8KFSpIko4cOSLp8pfZduvWTU2bNtU777zjsN9FRUVpx44dOnr0qJKTkxUVFaWoqCglJyfr0qVLSklJUWRkpKTC7WuSFBwcrICAgKtumzHmmtdHnT59Wr/99pseeeQRh/ZHHnlEaWlpDm316tXLM/+Vn51t27Zpz549KlmypL32MmXK6MKFC9q7d6+OHDmi3377TU2aNLlqXfmpUqWKSpYsaX9foUIF+89/586dunDhgh5//HGHn9usWbPsP7fu3btr7ty5euCBB/T6668rJSXFvqzOnTsrNTVVNWvWVO/evW/qeqTiJvfY+efXlClT7NOzs7P11ltvqXbt2vb9btWqVUV6bEpNTVXDhg0dRtuv5c+fN8nx/1uSvv76az3++OOqVKmSSpYsqY4dO+rYsWP6448/Cr2OtLQ0BQUFKSgoyN5Wq1YtlSpVymH/v9q+ZzVO/eLMvyJvb2/70PW4cePUqFEjDRs2TG+++ab9NMrHH3+shx56yGE+FxeXQi37anJyclShQgX7qYU/y70IrkKFCmrUqJHmzJmjhx9+WJ9++qleeukle7958+apb9++GjVqlBo0aKCSJUvqvffeu66h3+rVq9tPZVwp94NYo0YNSZeHbM0Vp1auvAi0devWCgoK0scff6yKFSsqJydHYWFhN31haOvWreXh4aEFCxbIw8NDmZmZxfZLWqdOnapLly6pUqVK9jZjjNzc3HTixAmVLl3a3v7nA3NuaMjd94YOHaoOHTpo6dKlWr58uYYMGaK5c+eqbdu2CgsLU9myZZWcnKzk5GQNHz5cQUFBeuutt7RlyxadP39ejz76qH1519rXpGvvs9LlfeHKgFKQK0NQfsEov3Ve2ZaTk5PvKVrp8oWcd911438XXvmLMfd0b+56JWnp0qUO/5eS7N9T1KJFCx08eFBLly7VV199pSZNmqhnz556//33VbduXe3fv1/Lly/XV199pWeffVZNmzbV559/fsP1Fhd/Pnbm+vXXX+3/HjVqlD744AONGTNG999/v7y9vdWnT59CHwdy/0//fLy58ljj5eV13XVf7f/74MGDatmypeLi4vTmm2+qTJky2rBhg2JjY696gf2VCvoD4Mr2q9ViNYQbJxsyZIhatGih7t27q2LFiqpUqZL27dun5557Lt/+uX9dZmdnX/e66tatq8OHD8vV1fWq5+Gfe+45/fOf/1T79u21d+9e+2iAJK1fv14REREOd3gVZlTpz9q3b68OHTpo8eLFea67GTVqlCpWrKjHH39c0uVfJD/99JNDn9TUVPuH9NixY0pLS9PkyZPVsGFDSdKGDRuuqx53d/d8f56urq7q1KmTpk+fLg8PD7Vr165Y3p1w6dIlzZo1S6NGjVJ0dLTDtGeeeUazZ89Wr169Cr28GjVqqEaNGurbt6/at2+v6dOnq23btvbrbr788kv99NNPatiwoUqWLKmsrCxNmjRJdevWtf9VWNh9rTA6dOigdu3a6csvv8xz3Y0xRqdPn5afn58qVqyoDRs26LHHHrNPT0lJ0YMPPnjd66xbt64SExNVrlw5+fr65tunSpUqWr16tRo1apTvdDc3t+v+nNaqVUseHh5KT0+3j4LlJyAgQJ07d1bnzp3VsGFDvfbaa3r//fclSb6+voqJiVFMTIz+9re/qXnz5jp+/LjKlClzXbXcadavX682bdro+eefl3Q5KO7evVuhoaGFmj93BDEjI0P/93//J0l5rgOrXbu2Zs6cqaysrOsavSnI1q1bdenSJY0aNcoerq68frGg49Of1apVS+np6Tp06JB99Gbnzp06depUobffajgt5WRRUVG677779Pbbb0u6/JdzQkKCxo4dq19++UU//vijpk+frtGjR0uSypUrJy8vL61YsUL/+9//dOrUqUKvq2nTpmrQoIGeeuoprVy5UgcOHFBKSor+9a9/aevWrfZ+Tz/9tE6fPq3u3burUaNGDn9BVqtWTVu3btXKlSv1yy+/aNCgQQ4XSxZGu3bt9NRTT6lTp06aOnWqDhw4oB9++EEvvfSSlixZok8++cR+4GjcuLG2bt2qWbNmaffu3RoyZIhD2CldurTKli2rjz76SHv27NGaNWsUHx9/XfVUqVJFZ8+e1erVq3X06FGH56Z069ZNa9as0fLly4vtKaklS5boxIkTio2NVVhYmMPrb3/7m6ZOnVqo5Zw/f169evXS2rVrdfDgQW3cuFFbtmxxODhGRUVpzpw5ql27tnx9fe2BZ/bs2YqKirL3K+y+VhjPPvusYmJi1L59eyUkJGjr1q06ePCglixZoqZNm+rrr7+WJL322msaOXKkEhMTtWvXLvXv31+pqal65ZVXrmt90uWA7+/vrzZt2mj9+vXav3+/kpOT9corr9hHC4YOHapRo0Zp3Lhx2r17t7777jt9+OGH9mXkhp/Dhw8X+llWJUuW1Kuvvqq+fftq5syZ2rt3r7Zv367x48fbbyoYPHiwvvzyS+3Zs0c7duzQkiVL7P9HH3zwgebOnauff/5Zv/zyiz777DOVL1/eMs9xuppq1aopKSlJKSkpSktL00svvaTDhw8Xen4vLy89/PDDeuedd7Rz506tW7dO//rXvxz69OrVS6dPn1a7du20detW7d69W//5z3+0a9euG6r5nnvu0aVLl/Thhx9q3759+s9//qNJkyY59Lna8SlX06ZNVbt2bT333HP67rvv9O2336pjx46KjIzM9zTsXwHhphiIj4/Xxx9/rEOHDqlbt26aMmWKZsyYofvvv1+RkZGaMWOG/ToSV1dXjRs3TpMnT1bFihXzvYOkIDabTcuWLdNjjz2mrl27qkaNGmrXrp0OHDigwMBAez9fX1+1bt1a33//fZ4RpLi4OD399NOKiYnRQw89pGPHjl33c3psNps+++wzvfHGG/rggw9Us2ZN1alTR59//rm2b9/u8Jdws2bNNGjQIL3++uuqX7++zpw5o44dO9qn33XXXZo7d662bdumsLAw9e3bV++999511RMREaG4uDjFxMQoICBA7777rn1a9erVFRERoZo1a+Y5VVhcTJ06VU2bNrXfNfRnzzzzjFJTU/Xdd99dczkuLi46duyYOnbsqBo1aujZZ59VixYtNGzYMHufRo0aKTs72yHIREZGKjs722GkobD7WmHYbDbNmTNHo0eP1oIFCxQZGanatWtr6NChatOmjf2Op969e6tfv37q16+f7r//fq1YsUKLFi1S9erVr2t9klSiRAmtW7dOlStX1tNPP63Q0FB17dpV58+ft4/kdOrUSWPGjNGECRN033336YknnnC4M2vUqFFKSkpSUFCQfSSgMN58800NHjxYCQkJCg0NVbNmzbR48WL7McDd3V0DBgxQ7dq19dhjj8nFxUVz586VJPn4+GjkyJGqV6+e6tevrwMHDmjZsmU3dRrtTjFo0CDVrVtXzZo1U1RUlMqXL3/dTwueNm2asrKyVK9ePb3yyisaMWKEw/SyZctqzZo1Onv2rCIjIxUeHq6PP/74hkdxHnjgAY0ePVojR45UWFiYZs+erYSEBIc+Vzs+5cp9YGTp0qX12GOPqWnTpqpataoSExNvqC4rsJkrL2gAnOC7775T06ZNFRsbe93h5FYyxujee+/VSy+9dN0jQgAA57B+nMcdoW7dulq9erW8vb2v+xqeW+XIkSMaPXq0/vvf/6pLly7OLgcAUEiM3AAFsNls8vf319ixY9WhQwdnlwMAKCTulgIKQO4HgDsTp6UAAIClEG4AAIClEG4AAIClEG4AAIClEG4A/GXlPvwMgLUQbgA4VefOnWWz2RQXF5dnWo8ePWSz2dS5c+dCLWvt2rWy2Ww6efJkofpnZGSoRYsW11EtgDsB4QaA0wUFBWnu3Lk6f/68ve3ChQv69NNPVbly5SJfX+43RZcvX97+bdsArINwA8Dp6tatq8qVK2v+/Pn2tvnz5+f5XiZjjN59911VrVpVXl5e9u8kk6QDBw7Yv5esdOnSDiM+UVFR6tWrl+Lj4+Xv72//1vkrT0v9+uuvateuncqUKSNvb2/Vq1dPmzdvvsVbD6Co8RA/AMVCly5dNH36dPuXtU6bNk1du3bV2rVr7X3+9a9/af78+Zo4caKqV6+udevW6fnnn1dAQIAeffRRffHFF3rmmWe0a9cu+fr6ysvLyz7vzJkz1b17d23cuDHfBzTmfhlipUqVtGjRIpUvX17fffedcnJybvm2AyhahBsAxcILL7ygAQMG6MCBA7LZbNq4caPmzp1rDzd//PGHRo8erTVr1qhBgwaSpKpVq2rDhg2aPHmyIiMjVaZMGUlSuXLlVKpUKYflV6tWLd9vVM41Z84c/f7779qyZYt9OdWqVSv6DQVwyxFuABQL/v7+atWqlWbOnCljjFq1aiV/f3/79J07d+rChQv2U0q5Ll686HDqqiD16tW76vTU1FT93//9nz3YALhzEW4AFBtdu3ZVr169JEnjx493mJZ7emjp0qWqVKmSw7TCXBTs7e191el/PoUF4M5GuAFQbDRv3tx+J1OzZs0cptWqVUseHh5KT09XZGRkvvO7u7tLkrKzs6973bVr19aUKVN0/PhxRm+AOxx3SwEoNlxcXJSWlqa0tDS5uLg4TCtZsqReffVV9e3bVzNnztTevXu1fft2jR8/XjNnzpQkBQcHy2azacmSJfr999919uzZQq+7ffv2Kl++vJ566ilt3LhR+/bt0xdffKFNmzYV6TYCuPUINwCKFV9fX/n6+uY77c0339TgwYOVkJCg0NBQNWvWTIsXL1ZISIgkqVKlSho2bJj69++vwMBA+ymuwnB3d9eqVatUrlw5tWzZUvfff7/eeeedPCELQPFnM/ndEwkAAHCHYuQGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYCuEGAABYyv8Dyj0LdT/O1QQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores(scores):\n",
    "    \"\"\"\n",
    "    Plot the evaluation scores.\n",
    "    \"\"\"\n",
    "    labels = [\"Retrieval Quality\", \"Answer Correctness\", \"Hallucination\"]\n",
    "    scores = [scores[\"retrieval_quality\"], scores[\"answer_correctness\"], scores[\"hallucination\"]]\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    ax.bar(labels, scores)\n",
    "    ax.set_xlabel('Metric')\n",
    "    # set y range to 0-1\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('RAG Evaluation Scores')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(results[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'When was MadeUpCompany founded and where is it headquartered?',\n",
       "  'retrieved_context': [Document(id='4b2b4488-cd9e-451c-8835-583f9617a416', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='891efd52-009b-4d26-9d2a-1a844c114030', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='977eae9e-ef15-418d-9fbe-baedb032ee18', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany was founded in 2010 and its headquarters is located in San Francisco, California. The company also has satellite offices globally, including in cities like New York, London, and Tokyo. This information indicates both the founding year and location of the main office.',\n",
       "  'expected_answer': 'MadeUpCompany was founded in 2010 and is headquartered in San Francisco, California.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact mentioned in documents',\n",
       "  'answer_correctness_reasoning': 'Answer is correct and more detailed',\n",
       "  'hallucination_reasoning': 'No extra information'},\n",
       " {'query': 'What security features does CloudMate offer for enterprise customers?',\n",
       "  'retrieved_context': [Document(id='0a1b807e-1725-40be-b713-92c5f03de150', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='309f4b50-a14a-41e2-b0c7-c19a5ff58b92', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='e8cac8f3-8b07-4805-806f-7bee6af9971c', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities')],\n",
       "  'generated_answer': ' \\nCloudMate offers several security features for enterprise customers, including military-grade encryption, multi-factor authentication, and role-based access control. These features provide a robust layer of protection against unauthorized access and ensure secure data management. Additionally, automated backups support business continuity in case of data loss or system failure.',\n",
       "  'expected_answer': 'CloudMate offers military-grade encryption, multi-factor authentication, and role-based access control for enterprise security.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 1,\n",
       "  'retrieval_quality_reasoning': 'Fact matches CloudMate features',\n",
       "  'answer_correctness_reasoning': 'More detailed than expected',\n",
       "  'hallucination_reasoning': 'Mentions business continuity'},\n",
       " {'query': 'How much does the Professional plan for CloudMate cost and what storage capacity does it include?',\n",
       "  'retrieved_context': [Document(id='4f083b61-0624-41ff-9f75-6ec6afd5dd41', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='39446eb9-3b13-44c5-87a1-13dd84376c19', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='25ff5e3e-20be-4799-bdf0-b62583f31fd0', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager')],\n",
       "  'generated_answer': ' The Professional plan for CloudMate costs $29.99 per month and includes a storage capacity of 1TB. This plan also offers enhanced security and priority support. It sits between the basic and enterprise options in terms of price and included features.',\n",
       "  'expected_answer': 'The Professional plan for CloudMate costs $29.99/month and includes 1TB of storage, enhanced security, and priority support.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0.5,\n",
       "  'retrieval_quality_reasoning': 'Fact present in all documents',\n",
       "  'answer_correctness_reasoning': 'Matches expected content',\n",
       "  'hallucination_reasoning': 'Extra information about plan position'},\n",
       " {'query': 'What analytics capabilities does DataWiz provide for business intelligence?',\n",
       "  'retrieved_context': [Document(id='ef7dd2e0-a44e-49a4-bb67-f36c484c83ba', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='9e94e54f-d669-439c-9ab1-e7a4dd3ac119', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='4e520c5c-2893-4a3b-a329-d438d01d89fb', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency')],\n",
       "  'generated_answer': ' \\nDataWiz provides various analytics capabilities including predictive analytics, real-time dashboards, API integrations, and automated anomaly detection. These features enable businesses to gain valuable insights from their data, such as demand forecasting and customer behavior modeling. The tool uses cutting-edge machine learning models to transform raw data into actionable insights.',\n",
       "  'expected_answer': 'DataWiz provides predictive analytics for demand forecasting and customer behavior modeling, real-time dashboards with customizable reporting, API integrations with popular business intelligence tools, and automated anomaly detection.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact fully described',\n",
       "  'answer_correctness_reasoning': 'Similar content, more details',\n",
       "  'hallucination_reasoning': 'Answer is fully supported'},\n",
       " {'query': 'What compliance standards does MadeUpCompany adhere to?',\n",
       "  'retrieved_context': [Document(id='c6143988-259a-4677-93a0-b64b58a0be87', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='8068d6da-5972-47ba-aabc-817499e99c00', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='eef82762-9f04-48da-bd75-0355929c318b', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany adheres to several key compliance standards, specifically GDPR, HIPAA, and SOC 2 Compliance. These ensure global security and data protection compliance. The company also implements additional security measures such as end-to-end encryption and zero trust architecture.',\n",
       "  'expected_answer': 'MadeUpCompany adheres to GDPR, HIPAA, and SOC 2 compliance standards for global security and data protection compliance.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact explicitly mentioned',\n",
       "  'answer_correctness_reasoning': 'More detailed than expected',\n",
       "  'hallucination_reasoning': 'No unsupported information'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"individual_results\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don't know much about MadeUpCompany except that their website is www.madeupcompany.com and they have a sales email address (sales@madeupcompany.com). The provided documents only contain this basic contact information. There's no additional details available in the given context.\n"
     ]
    }
   ],
   "source": [
    "# Adjustment 2: Adjust LLM decoding parameters\n",
    "llm.params[GenParams.TEMPERATURE] = 0.7\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same facts' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 1/25 [00:13<05:33, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/25 [00:24<04:39, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Mentions business continuity' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Equivalent content' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 3/25 [00:35<04:09, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Extra information about plan position' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully described' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 4/25 [00:47<04:04, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact explicitly stated' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 5/25 [00:57<03:44, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 6/25 [01:10<03:41, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches document content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Matches expected answer' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 7/25 [01:21<03:27, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [01:32<03:13, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupportable claims' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [01:43<02:57, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches company values' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [01:53<02:44, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Minor inference, not direct quote' score=0.5\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [02:05<02:36, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No unsupported info' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [02:15<02:21, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added unsuppoted plan analysis' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact matches document content' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [02:29<02:20, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [02:42<02:13, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact fully present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is accurate' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [02:52<01:55, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is correct' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [03:03<01:42, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Encryption method mentioned' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [03:15<01:32, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is fully supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact found in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [03:26<01:20, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Mentions unfounded comparisons' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in all documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed, same core answer' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [03:38<01:09, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is directly supported' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [03:49<00:57, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning=\"Adds 'unusual patterns' detail\" score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact is present' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [04:02<00:47, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning=\"Adds 'unused service time' detail\" score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='No trend forecasting mentioned' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Lacks specific information' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [04:14<00:35, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='No new info introduced' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Only flexible pricing mentioned' score=0\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Lacks specific details' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [04:27<00:24, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer admits lack of knowledge' score=0\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact mentioned in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='Generated answer is more detailed' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [04:41<00:12, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Added unsuppported environmental impact detail' score=1\n",
      "[evaluation_retrieval_quality] LLM response: reasoning='Fact present in documents' score=1\n",
      "[evaluation_answer_correctness] LLM response: reasoning='More detailed than expected' score=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [04:55<00:00, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[evaluation_hallucination] LLM response: reasoning='Answer is supported by documents' score=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'retrieval_quality': 0.92, 'answer_correctness': 0.92, 'hallucination': 0.28}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_rag_system(\n",
    "    graph, \n",
    "    sample_queries,\n",
    "    expected_responses,\n",
    "    evaluator=RAGEvaluator(llm_func=call_judge),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "results[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores(scores):\n",
    "    \"\"\"\n",
    "    Plot the evaluation scores.\n",
    "    \"\"\"\n",
    "    labels = [\"Retrieval Quality\", \"Answer Correctness\", \"Hallucination\"]\n",
    "    scores = [scores[\"retrieval_quality\"], scores[\"answer_correctness\"], scores[\"hallucination\"]]\n",
    "    \n",
    "    _, ax = plt.subplots()\n",
    "    ax.bar(labels, scores)\n",
    "    ax.set_xlabel('Metric')\n",
    "    # set y range to 0-1\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('RAG Evaluation Scores')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores(results[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'When was MadeUpCompany founded and where is it headquartered?',\n",
       "  'retrieved_context': [Document(id='4b2b4488-cd9e-451c-8835-583f9617a416', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='891efd52-009b-4d26-9d2a-1a844c114030', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.'),\n",
       "   Document(id='977eae9e-ef15-418d-9fbe-baedb032ee18', metadata={'Header 1': 'About MadeUpCompany'}, page_content='[About MadeUpCompany]: \\nMadeUpCompany is a pioneering technology firm founded in 2010, specializing in cloud computing, data analytics, and machine learning. Headquartered in San Francisco, California, we have a global presence with satellite offices in New York, London, and Tokyo. Our mission is to empower businesses and individuals with cutting-edge technology that enhances efficiency, scalability, and innovation.  \\nWith a diverse team of experts from various industriesâ€”including AI research, cybersecurity, and enterprise software developmentâ€”we push the boundaries of whatâ€™s possible. Our commitment to continuous improvement, security, and customer success has earned us recognition as a leader in the tech space.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany was founded in 2010 and its headquarters is located in San Francisco, California. The company also has satellite offices globally, including in cities like New York, London, and Tokyo. This information indicates both the founding year and location of the main office.',\n",
       "  'expected_answer': 'MadeUpCompany was founded in 2010 and is headquartered in San Francisco, California.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact mentioned in documents',\n",
       "  'answer_correctness_reasoning': 'More detailed, same facts',\n",
       "  'hallucination_reasoning': 'Answer fully supported'},\n",
       " {'query': 'What security features does CloudMate offer for enterprise customers?',\n",
       "  'retrieved_context': [Document(id='0a1b807e-1725-40be-b713-92c5f03de150', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='309f4b50-a14a-41e2-b0c7-c19a5ff58b92', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities'),\n",
       "   Document(id='e8cac8f3-8b07-4805-806f-7bee6af9971c', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'CloudMate â€“ Secure and Scalable Cloud Storage'}, page_content='[About MadeUpCompany/Products and Services/CloudMate â€“ Secure and Scalable Cloud Storage]: \\nCloudMate is our flagship cloud storage solution, designed for businesses of all sizes. Features include:\\n- âœ… Seamless data migration with automated backups\\n- âœ… Military-grade encryption and multi-factor authentication\\n- âœ… Role-based access control for enterprise security\\n- âœ… AI-powered file organization and search capabilities')],\n",
       "  'generated_answer': ' \\nCloudMate offers several security features for enterprise customers, including military-grade encryption, multi-factor authentication, and role-based access control. These features provide a robust layer of protection against unauthorized access and ensure secure data management. Additionally, automated backups support business continuity in case of data loss or system failure.',\n",
       "  'expected_answer': 'CloudMate offers military-grade encryption, multi-factor authentication, and role-based access control for enterprise security.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 1,\n",
       "  'retrieval_quality_reasoning': 'Fact mentioned in documents',\n",
       "  'answer_correctness_reasoning': 'More detailed than expected',\n",
       "  'hallucination_reasoning': 'Mentions business continuity'},\n",
       " {'query': 'How much does the Professional plan for CloudMate cost and what storage capacity does it include?',\n",
       "  'retrieved_context': [Document(id='4f083b61-0624-41ff-9f75-6ec6afd5dd41', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='39446eb9-3b13-44c5-87a1-13dd84376c19', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager'),\n",
       "   Document(id='25ff5e3e-20be-4799-bdf0-b62583f31fd0', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Pricing', 'Header 3': 'CloudMate Plans'}, page_content='[About MadeUpCompany/Pricing/CloudMate Plans]: \\nOur secure and scalable cloud storage service, CloudMate, is available in the following plans:\\n- Basic: $9.99/month â€“ 100GB storage, essential security features\\n- Professional: $29.99/month â€“ 1TB storage, enhanced security, priority support\\n- Enterprise: Custom pricing â€“ Unlimited storage, advanced compliance tools, dedicated account manager')],\n",
       "  'generated_answer': ' The Professional plan for CloudMate costs $29.99 per month and includes a storage capacity of 1TB. This plan also offers enhanced security and priority support. It sits between the basic and enterprise options in terms of price and included features.',\n",
       "  'expected_answer': 'The Professional plan for CloudMate costs $29.99/month and includes 1TB of storage, enhanced security, and priority support.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0.5,\n",
       "  'retrieval_quality_reasoning': 'Fact mentioned in documents',\n",
       "  'answer_correctness_reasoning': 'Equivalent content',\n",
       "  'hallucination_reasoning': 'Extra information about plan position'},\n",
       " {'query': 'What analytics capabilities does DataWiz provide for business intelligence?',\n",
       "  'retrieved_context': [Document(id='ef7dd2e0-a44e-49a4-bb67-f36c484c83ba', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='9e94e54f-d669-439c-9ab1-e7a4dd3ac119', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency'),\n",
       "   Document(id='4e520c5c-2893-4a3b-a329-d438d01d89fb', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Products and Services', 'Header 3': 'DataWiz â€“ Advanced Data Analytics'}, page_content='[About MadeUpCompany/Products and Services/DataWiz â€“ Advanced Data Analytics]: \\nDataWiz transforms raw data into actionable insights using cutting-edge machine learning models. Features include:\\n- ðŸ“Š Predictive analytics for demand forecasting and customer behavior modeling\\n- ðŸ“Š Real-time dashboards with customizable reporting\\n- ðŸ“Š API integrations with popular business intelligence tools\\n- ðŸ“Š Automated anomaly detection for fraud prevention and operational efficiency')],\n",
       "  'generated_answer': \" \\nDataWiz provides various analytics capabilities including predictive analytics, real-time dashboards, API integrations, and automated anomaly detection. These features enable businesses to gain valuable insights from their data, facilitating informed decision-making. The platform's advanced data analytics transform raw data into actionable insights using cutting-edge machine learning models.\",\n",
       "  'expected_answer': 'DataWiz provides predictive analytics for demand forecasting and customer behavior modeling, real-time dashboards with customizable reporting, API integrations with popular business intelligence tools, and automated anomaly detection.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact fully described',\n",
       "  'answer_correctness_reasoning': 'Generated answer is more detailed',\n",
       "  'hallucination_reasoning': 'No unsupported info'},\n",
       " {'query': 'What compliance standards does MadeUpCompany adhere to?',\n",
       "  'retrieved_context': [Document(id='c6143988-259a-4677-93a0-b64b58a0be87', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='8068d6da-5972-47ba-aabc-817499e99c00', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.'),\n",
       "   Document(id='eef82762-9f04-48da-bd75-0355929c318b', metadata={'Header 1': 'About MadeUpCompany', 'Header 2': 'Security and Compliance'}, page_content='[About MadeUpCompany/Security and Compliance]: \\nSecurity is at the heart of everything we do. MadeUpCompany adheres to the highest security and regulatory standards, including:  \\n- ðŸ”’ GDPR, HIPAA, and SOC 2 Compliance â€“ Ensuring global security and data protection compliance.\\n- ðŸ”’ End-to-End Encryption â€“ Protecting data in transit and at rest with AES-256 encryption.\\n- ðŸ”’ Zero Trust Architecture â€“ Implementing rigorous access control and continuous authentication.\\n- ðŸ”’ DDoS Protection & Advanced Threat Detection â€“ Safeguarding against cyber threats with AI-powered monitoring.  \\nOur team continuously updates security measures to stay ahead of evolving cyber risks.')],\n",
       "  'generated_answer': ' \\nMadeUpCompany adheres to several key compliance standards, specifically GDPR, HIPAA, and SOC 2 Compliance. These ensure global security and data protection compliance. The company also implements additional security measures such as end-to-end encryption and zero trust architecture.',\n",
       "  'expected_answer': 'MadeUpCompany adheres to GDPR, HIPAA, and SOC 2 compliance standards for global security and data protection compliance.',\n",
       "  'retrieval_quality': 1,\n",
       "  'answer_correctness': 1,\n",
       "  'hallucination_score': 0,\n",
       "  'retrieval_quality_reasoning': 'Fact explicitly stated',\n",
       "  'answer_correctness_reasoning': 'More detailed than expected',\n",
       "  'hallucination_reasoning': 'Answer is directly supported'}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"individual_results\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "\n",
    "- Hyperparameter Tuning: The top-k parameter in the retrieval process was adjusted to experiment with the number of documents retrieved for context. Increasing top-k to 5 improved retrieval quality by providing more context, but further increases introduced irrelevant documents, reducing overall performance.\n",
    "- Temperature: The temperature parameter for the LLM was modified to 0.7 to allow for more diverse and creative responses. This also reduced performance as more diverse outputs not necessarily is the parameter we are trying to improve.\n",
    "- New models: other ideas for improvement could be to change the model to one with more parameters, as it (perhaps) would be able to process the inputs better.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
